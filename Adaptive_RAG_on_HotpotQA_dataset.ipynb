{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bc5df6b",
   "metadata": {
    "id": "3bc5df6b"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6707adde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uU1axQkkLRsk",
   "metadata": {
    "id": "uU1axQkkLRsk"
   },
   "outputs": [],
   "source": [
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"xxx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a766dcb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8a766dcb",
    "outputId": "6db17c7c-7a7b-4218-a288-a70cef2fc6ac"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1303baa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>answer</th>\n",
       "      <th>question</th>\n",
       "      <th>supporting_facts</th>\n",
       "      <th>context</th>\n",
       "      <th>type</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5abc0a5d5542993f40c73c64</td>\n",
       "      <td>no</td>\n",
       "      <td>Are Freakonomics and In the Realm of the Hacke...</td>\n",
       "      <td>[['Freakonomics (film)', 0], ['In the Realm of...</td>\n",
       "      <td>[['Hackers (film)', ['Hackers is a 1995 Americ...</td>\n",
       "      <td>comparison</td>\n",
       "      <td>hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5a760ab65542994ccc918697</td>\n",
       "      <td>Nelson Rockefeller</td>\n",
       "      <td>Alfred Balk served as the secretary of the Com...</td>\n",
       "      <td>[['Alfred Balk', 0], ['Alfred Balk', 2], ['Nel...</td>\n",
       "      <td>[['Cynthia Hogan', ['Cynthia C. Hogan (born Ci...</td>\n",
       "      <td>bridge</td>\n",
       "      <td>hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5a8a43eb5542996c9b8d5e82</td>\n",
       "      <td>Marion, South Australia</td>\n",
       "      <td>Which Australian city founded in 1838 contains...</td>\n",
       "      <td>[['Westminster School, Adelaide', 0], ['Westmi...</td>\n",
       "      <td>[['Sainik School Balachadi, Jamnagar', ['The S...</td>\n",
       "      <td>bridge</td>\n",
       "      <td>hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5ae7ba7a5542993210983f12</td>\n",
       "      <td>Usher</td>\n",
       "      <td>What is the name of the singer who's song was ...</td>\n",
       "      <td>[[\"I Don't Wanna Know\", 1], ['Yeah! (Usher son...</td>\n",
       "      <td>[[\"Can't Touch It\", ['\"Can\\'t Touch It\" is a s...</td>\n",
       "      <td>bridge</td>\n",
       "      <td>hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5aba7cfe554299232ef4a2fd</td>\n",
       "      <td>Carabao Cup</td>\n",
       "      <td>The 2017‚Äì18 Wigan Athletic F.C. season will be...</td>\n",
       "      <td>[['2017‚Äì18 Wigan Athletic F.C. season', 1], ['...</td>\n",
       "      <td>[['2017‚Äì18 Wigan Athletic F.C. season', [\"The ...</td>\n",
       "      <td>bridge</td>\n",
       "      <td>hard</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id                   answer  \\\n",
       "0  5abc0a5d5542993f40c73c64                       no   \n",
       "1  5a760ab65542994ccc918697       Nelson Rockefeller   \n",
       "2  5a8a43eb5542996c9b8d5e82  Marion, South Australia   \n",
       "3  5ae7ba7a5542993210983f12                    Usher   \n",
       "4  5aba7cfe554299232ef4a2fd              Carabao Cup   \n",
       "\n",
       "                                            question  \\\n",
       "0  Are Freakonomics and In the Realm of the Hacke...   \n",
       "1  Alfred Balk served as the secretary of the Com...   \n",
       "2  Which Australian city founded in 1838 contains...   \n",
       "3  What is the name of the singer who's song was ...   \n",
       "4  The 2017‚Äì18 Wigan Athletic F.C. season will be...   \n",
       "\n",
       "                                    supporting_facts  \\\n",
       "0  [['Freakonomics (film)', 0], ['In the Realm of...   \n",
       "1  [['Alfred Balk', 0], ['Alfred Balk', 2], ['Nel...   \n",
       "2  [['Westminster School, Adelaide', 0], ['Westmi...   \n",
       "3  [[\"I Don't Wanna Know\", 1], ['Yeah! (Usher son...   \n",
       "4  [['2017‚Äì18 Wigan Athletic F.C. season', 1], ['...   \n",
       "\n",
       "                                             context        type level  \n",
       "0  [['Hackers (film)', ['Hackers is a 1995 Americ...  comparison  hard  \n",
       "1  [['Cynthia Hogan', ['Cynthia C. Hogan (born Ci...      bridge  hard  \n",
       "2  [['Sainik School Balachadi, Jamnagar', ['The S...      bridge  hard  \n",
       "3  [[\"Can't Touch It\", ['\"Can\\'t Touch It\" is a s...      bridge  hard  \n",
       "4  [['2017‚Äì18 Wigan Athletic F.C. season', [\"The ...      bridge  hard  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Input_Data/test_subsampled.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f44baf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['question','context','answer']]\n",
    "df = df.sample(frac=1, random_state=42)\n",
    "df = df.reset_index(drop=True)\n",
    "df = pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ggUzVW4AQ6PU",
   "metadata": {
    "id": "ggUzVW4AQ6PU"
   },
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "import ast\n",
    "# Function to count tokens in a string using tiktoken\n",
    "def count_tokens(text):\n",
    "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    return len(encoding.encode(text))\n",
    "\n",
    "# Function to safely parse context - handles both string and list formats\n",
    "def parse_context(context):\n",
    "    \"\"\"\n",
    "    Parse context whether it's stored as string representation of list or actual list\n",
    "    \"\"\"\n",
    "    if isinstance(context, str):\n",
    "        try:\n",
    "            # Try to parse as literal (for string representations of lists)\n",
    "            parsed = ast.literal_eval(context)\n",
    "            return parsed\n",
    "        except (ValueError, SyntaxError):\n",
    "            # If it's just a plain string, return as is\n",
    "            return context\n",
    "    else:\n",
    "        # If it's already a list or other structure, return as is\n",
    "        return context\n",
    "\n",
    "# Function to count tokens for nested context structure\n",
    "def count_context_tokens(context):\n",
    "    \"\"\"\n",
    "    Count tokens in context, handling different possible formats\n",
    "    \"\"\"\n",
    "    total_tokens = 0\n",
    "    \n",
    "    # First parse the context\n",
    "    parsed_context = parse_context(context)\n",
    "    \n",
    "    # Handle different formats\n",
    "    if isinstance(parsed_context, list):\n",
    "        for item in parsed_context:\n",
    "            if isinstance(item, (list, tuple)) and len(item) >= 2:\n",
    "                # Expected format: [title, text_snippets]\n",
    "                title = item[0]\n",
    "                text_snippets = item[1]\n",
    "                \n",
    "                # Count tokens in title\n",
    "                if isinstance(title, str):\n",
    "                    total_tokens += count_tokens(title)\n",
    "                \n",
    "                # Count tokens in text snippets\n",
    "                if isinstance(text_snippets, list):\n",
    "                    for snippet in text_snippets:\n",
    "                        if isinstance(snippet, str):\n",
    "                            total_tokens += count_tokens(snippet)\n",
    "                elif isinstance(text_snippets, str):\n",
    "                    total_tokens += count_tokens(text_snippets)\n",
    "            else:\n",
    "                # Handle single items or unexpected formats\n",
    "                if isinstance(item, str):\n",
    "                    total_tokens += count_tokens(item)\n",
    "    elif isinstance(parsed_context, str):\n",
    "        # If it's just a string, count tokens directly\n",
    "        total_tokens += count_tokens(parsed_context)\n",
    "    \n",
    "    return total_tokens\n",
    "\n",
    "\n",
    "# Apply the count_context_tokens function to the 'context' column\n",
    "df['context_token_count'] = df['context'].apply(count_context_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a6447f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>answer</th>\n",
       "      <th>context_token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cagliostro-Walzer op.370 was composed by a man...</td>\n",
       "      <td>[['Jiroemon Kimura', ['Jiroemon Kimura (Êú®Êùë Ê¨°ÈÉéÂè≥...</td>\n",
       "      <td>1825</td>\n",
       "      <td>1754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What album did John Lennon release before the ...</td>\n",
       "      <td>[['Instant Karma: All-Time Greatest Hits', [\"I...</td>\n",
       "      <td>John Lennon/Plastic Ono Band</td>\n",
       "      <td>1350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Which actor in The Lieutenant Wears Skirts is ...</td>\n",
       "      <td>[['The Lieutenant Wore Skirts', ['The Lieutena...</td>\n",
       "      <td>Tom Ewell</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In what year was the Sayrevill, New Jersey roc...</td>\n",
       "      <td>[['The Rats (American band)', ['The Rats were ...</td>\n",
       "      <td>1983</td>\n",
       "      <td>1516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which genus has the most number of species, My...</td>\n",
       "      <td>[['Styrax crotonoides', ['Styrax crotonoides i...</td>\n",
       "      <td>Myrsine</td>\n",
       "      <td>824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>Luke Rockhold defeated the MMA fighter who was...</td>\n",
       "      <td>[['Kamen Georgiev', ['Kamen Georgiev (Bulgaria...</td>\n",
       "      <td>Anderson Silva</td>\n",
       "      <td>1559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>Who was born first, Brooklyn Decker or Andy Ro...</td>\n",
       "      <td>[['Brooklyn Decker', ['Brooklyn Danielle Decke...</td>\n",
       "      <td>Andrew Stephen Roddick</td>\n",
       "      <td>1339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>Which Outer Banks landmark and premiere BBQ re...</td>\n",
       "      <td>[[\"The Park's Finest\", ['The Park‚Äôs Finest is ...</td>\n",
       "      <td>Pigman's Bar-B-Que</td>\n",
       "      <td>1178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>What is the name of the largest shipping facil...</td>\n",
       "      <td>[['Transportation in Boston', ['The Boston tra...</td>\n",
       "      <td>Port of Boston</td>\n",
       "      <td>1227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>the first woman to be the chef de mission of a...</td>\n",
       "      <td>[['Australia at the 2012 Winter Youth Olympics...</td>\n",
       "      <td>2002 Winter Olympics</td>\n",
       "      <td>1234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question  \\\n",
       "0    Cagliostro-Walzer op.370 was composed by a man...   \n",
       "1    What album did John Lennon release before the ...   \n",
       "2    Which actor in The Lieutenant Wears Skirts is ...   \n",
       "3    In what year was the Sayrevill, New Jersey roc...   \n",
       "4    Which genus has the most number of species, My...   \n",
       "..                                                 ...   \n",
       "495  Luke Rockhold defeated the MMA fighter who was...   \n",
       "496  Who was born first, Brooklyn Decker or Andy Ro...   \n",
       "497  Which Outer Banks landmark and premiere BBQ re...   \n",
       "498  What is the name of the largest shipping facil...   \n",
       "499  the first woman to be the chef de mission of a...   \n",
       "\n",
       "                                               context  \\\n",
       "0    [['Jiroemon Kimura', ['Jiroemon Kimura (Êú®Êùë Ê¨°ÈÉéÂè≥...   \n",
       "1    [['Instant Karma: All-Time Greatest Hits', [\"I...   \n",
       "2    [['The Lieutenant Wore Skirts', ['The Lieutena...   \n",
       "3    [['The Rats (American band)', ['The Rats were ...   \n",
       "4    [['Styrax crotonoides', ['Styrax crotonoides i...   \n",
       "..                                                 ...   \n",
       "495  [['Kamen Georgiev', ['Kamen Georgiev (Bulgaria...   \n",
       "496  [['Brooklyn Decker', ['Brooklyn Danielle Decke...   \n",
       "497  [[\"The Park's Finest\", ['The Park‚Äôs Finest is ...   \n",
       "498  [['Transportation in Boston', ['The Boston tra...   \n",
       "499  [['Australia at the 2012 Winter Youth Olympics...   \n",
       "\n",
       "                           answer  context_token_count  \n",
       "0                            1825                 1754  \n",
       "1    John Lennon/Plastic Ono Band                 1350  \n",
       "2                       Tom Ewell                 1050  \n",
       "3                            1983                 1516  \n",
       "4                         Myrsine                  824  \n",
       "..                            ...                  ...  \n",
       "495                Anderson Silva                 1559  \n",
       "496        Andrew Stephen Roddick                 1339  \n",
       "497            Pigman's Bar-B-Que                 1178  \n",
       "498                Port of Boston                 1227  \n",
       "499          2002 Winter Olympics                 1234  \n",
       "\n",
       "[500 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "n77HIUa2btL0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n77HIUa2btL0",
    "outputId": "afe74f8a-4b48-4672-959a-730c46800b15"
   },
   "outputs": [],
   "source": [
    "# Find the maximum token count\n",
    "max_tokens = df['context_token_count'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "CXqZ6vzveUXo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 431
    },
    "id": "CXqZ6vzveUXo",
    "outputId": "b65e107f-ad9d-4c8c-c595-38fc045f04fe"
   },
   "outputs": [],
   "source": [
    "# Function to flatten context for processing\n",
    "def flatten_context(context):\n",
    "    \"\"\"\n",
    "    Flatten context into a single string, handling different formats\n",
    "    \"\"\"\n",
    "    parsed_context = parse_context(context)\n",
    "    \n",
    "    if isinstance(parsed_context, list):\n",
    "        flattened_parts = []\n",
    "        for item in parsed_context:\n",
    "            if isinstance(item, (list, tuple)) and len(item) >= 2:\n",
    "                # Expected format: [title, text_snippets]\n",
    "                title = item[0]\n",
    "                text_snippets = item[1]\n",
    "                \n",
    "                # Add title\n",
    "                if isinstance(title, str):\n",
    "                    flattened_parts.append(title)\n",
    "                \n",
    "                # Add text snippets\n",
    "                if isinstance(text_snippets, list):\n",
    "                    for snippet in text_snippets:\n",
    "                        if isinstance(snippet, str):\n",
    "                            flattened_parts.append(snippet)\n",
    "                elif isinstance(text_snippets, str):\n",
    "                    flattened_parts.append(text_snippets)\n",
    "            else:\n",
    "                # Handle single items\n",
    "                if isinstance(item, str):\n",
    "                    flattened_parts.append(item)\n",
    "        \n",
    "        return \" \".join(flattened_parts)\n",
    "    elif isinstance(parsed_context, str):\n",
    "        return parsed_context\n",
    "    else:\n",
    "        return str(parsed_context)\n",
    "\n",
    "df['raw_context'] = df['context'].apply(flatten_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "MxJsZaN9i2tp",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "MxJsZaN9i2tp",
    "outputId": "6465cfb0-8b17-4bb7-e532-b727e2438b83"
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# df.context_token_count.hist(bins=100)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64abee1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>answer</th>\n",
       "      <th>context_token_count</th>\n",
       "      <th>raw_context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cagliostro-Walzer op.370 was composed by a man...</td>\n",
       "      <td>[['Jiroemon Kimura', ['Jiroemon Kimura (Êú®Êùë Ê¨°ÈÉéÂè≥...</td>\n",
       "      <td>1825</td>\n",
       "      <td>1754</td>\n",
       "      <td>Jiroemon Kimura Jiroemon Kimura (Êú®Êùë Ê¨°ÈÉéÂè≥Ë°õÈñÄ , Ki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What album did John Lennon release before the ...</td>\n",
       "      <td>[['Instant Karma: All-Time Greatest Hits', [\"I...</td>\n",
       "      <td>John Lennon/Plastic Ono Band</td>\n",
       "      <td>1350</td>\n",
       "      <td>Instant Karma: All-Time Greatest Hits Instant ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Which actor in The Lieutenant Wears Skirts is ...</td>\n",
       "      <td>[['The Lieutenant Wore Skirts', ['The Lieutena...</td>\n",
       "      <td>Tom Ewell</td>\n",
       "      <td>1050</td>\n",
       "      <td>The Lieutenant Wore Skirts The Lieutenant Wore...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In what year was the Sayrevill, New Jersey roc...</td>\n",
       "      <td>[['The Rats (American band)', ['The Rats were ...</td>\n",
       "      <td>1983</td>\n",
       "      <td>1516</td>\n",
       "      <td>The Rats (American band) The Rats were an Amer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which genus has the most number of species, My...</td>\n",
       "      <td>[['Styrax crotonoides', ['Styrax crotonoides i...</td>\n",
       "      <td>Myrsine</td>\n",
       "      <td>824</td>\n",
       "      <td>Styrax crotonoides Styrax crotonoides is a spe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>Luke Rockhold defeated the MMA fighter who was...</td>\n",
       "      <td>[['Kamen Georgiev', ['Kamen Georgiev (Bulgaria...</td>\n",
       "      <td>Anderson Silva</td>\n",
       "      <td>1559</td>\n",
       "      <td>Kamen Georgiev Kamen Georgiev (Bulgarian: –ö–∞–º–µ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>Who was born first, Brooklyn Decker or Andy Ro...</td>\n",
       "      <td>[['Brooklyn Decker', ['Brooklyn Danielle Decke...</td>\n",
       "      <td>Andrew Stephen Roddick</td>\n",
       "      <td>1339</td>\n",
       "      <td>Brooklyn Decker Brooklyn Danielle Decker Roddi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>Which Outer Banks landmark and premiere BBQ re...</td>\n",
       "      <td>[[\"The Park's Finest\", ['The Park‚Äôs Finest is ...</td>\n",
       "      <td>Pigman's Bar-B-Que</td>\n",
       "      <td>1178</td>\n",
       "      <td>The Park's Finest The Park‚Äôs Finest is a Filip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>What is the name of the largest shipping facil...</td>\n",
       "      <td>[['Transportation in Boston', ['The Boston tra...</td>\n",
       "      <td>Port of Boston</td>\n",
       "      <td>1227</td>\n",
       "      <td>Transportation in Boston The Boston transporta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>the first woman to be the chef de mission of a...</td>\n",
       "      <td>[['Australia at the 2012 Winter Youth Olympics...</td>\n",
       "      <td>2002 Winter Olympics</td>\n",
       "      <td>1234</td>\n",
       "      <td>Australia at the 2012 Winter Youth Olympics Au...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question  \\\n",
       "0    Cagliostro-Walzer op.370 was composed by a man...   \n",
       "1    What album did John Lennon release before the ...   \n",
       "2    Which actor in The Lieutenant Wears Skirts is ...   \n",
       "3    In what year was the Sayrevill, New Jersey roc...   \n",
       "4    Which genus has the most number of species, My...   \n",
       "..                                                 ...   \n",
       "495  Luke Rockhold defeated the MMA fighter who was...   \n",
       "496  Who was born first, Brooklyn Decker or Andy Ro...   \n",
       "497  Which Outer Banks landmark and premiere BBQ re...   \n",
       "498  What is the name of the largest shipping facil...   \n",
       "499  the first woman to be the chef de mission of a...   \n",
       "\n",
       "                                               context  \\\n",
       "0    [['Jiroemon Kimura', ['Jiroemon Kimura (Êú®Êùë Ê¨°ÈÉéÂè≥...   \n",
       "1    [['Instant Karma: All-Time Greatest Hits', [\"I...   \n",
       "2    [['The Lieutenant Wore Skirts', ['The Lieutena...   \n",
       "3    [['The Rats (American band)', ['The Rats were ...   \n",
       "4    [['Styrax crotonoides', ['Styrax crotonoides i...   \n",
       "..                                                 ...   \n",
       "495  [['Kamen Georgiev', ['Kamen Georgiev (Bulgaria...   \n",
       "496  [['Brooklyn Decker', ['Brooklyn Danielle Decke...   \n",
       "497  [[\"The Park's Finest\", ['The Park‚Äôs Finest is ...   \n",
       "498  [['Transportation in Boston', ['The Boston tra...   \n",
       "499  [['Australia at the 2012 Winter Youth Olympics...   \n",
       "\n",
       "                           answer  context_token_count  \\\n",
       "0                            1825                 1754   \n",
       "1    John Lennon/Plastic Ono Band                 1350   \n",
       "2                       Tom Ewell                 1050   \n",
       "3                            1983                 1516   \n",
       "4                         Myrsine                  824   \n",
       "..                            ...                  ...   \n",
       "495                Anderson Silva                 1559   \n",
       "496        Andrew Stephen Roddick                 1339   \n",
       "497            Pigman's Bar-B-Que                 1178   \n",
       "498                Port of Boston                 1227   \n",
       "499          2002 Winter Olympics                 1234   \n",
       "\n",
       "                                           raw_context  \n",
       "0    Jiroemon Kimura Jiroemon Kimura (Êú®Êùë Ê¨°ÈÉéÂè≥Ë°õÈñÄ , Ki...  \n",
       "1    Instant Karma: All-Time Greatest Hits Instant ...  \n",
       "2    The Lieutenant Wore Skirts The Lieutenant Wore...  \n",
       "3    The Rats (American band) The Rats were an Amer...  \n",
       "4    Styrax crotonoides Styrax crotonoides is a spe...  \n",
       "..                                                 ...  \n",
       "495  Kamen Georgiev Kamen Georgiev (Bulgarian: –ö–∞–º–µ...  \n",
       "496  Brooklyn Decker Brooklyn Danielle Decker Roddi...  \n",
       "497  The Park's Finest The Park‚Äôs Finest is a Filip...  \n",
       "498  Transportation in Boston The Boston transporta...  \n",
       "499  Australia at the 2012 Winter Youth Olympics Au...  \n",
       "\n",
       "[500 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d4f05e7",
   "metadata": {
    "id": "9d4f05e7"
   },
   "outputs": [],
   "source": [
    "# Function to create chunks with overlap while preserving sentence boundaries\n",
    "def create_chunks(text, chunk_size=256, overlap=64):\n",
    "    # Split text into sentences using newlines\n",
    "    sentences = text.split('\\n')\n",
    "\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_length = 0\n",
    "\n",
    "    i = 0\n",
    "    while i < len(sentences):\n",
    "        sentence = sentences[i]\n",
    "        sentence_length = count_tokens(sentence)\n",
    "\n",
    "        # If adding this sentence would exceed chunk size, finalize current chunk\n",
    "        if current_length + sentence_length > chunk_size and current_chunk:\n",
    "            # Join current chunk sentences\n",
    "            chunk_text = '\\n'.join(current_chunk)\n",
    "            chunks.append(chunk_text)\n",
    "\n",
    "            # Create overlap for next chunk\n",
    "            overlap_chunk = []\n",
    "            overlap_length = 0\n",
    "\n",
    "            # Go backwards from current position to create overlap\n",
    "            j = len(current_chunk) - 1\n",
    "            while j >= 0 and overlap_length < overlap:\n",
    "                overlap_sentence = current_chunk[j]\n",
    "                overlap_sentence_length = count_tokens(overlap_sentence)\n",
    "\n",
    "                if overlap_length + overlap_sentence_length <= overlap:\n",
    "                    overlap_chunk.insert(0, overlap_sentence)\n",
    "                    overlap_length += overlap_sentence_length\n",
    "                    j -= 1\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "            # Start new chunk with overlap\n",
    "            current_chunk = overlap_chunk\n",
    "            current_length = overlap_length\n",
    "\n",
    "        # Add current sentence to chunk\n",
    "        current_chunk.append(sentence)\n",
    "        current_length += sentence_length\n",
    "        i += 1\n",
    "\n",
    "    # Add the last chunk if it has content\n",
    "    if current_chunk:\n",
    "        chunk_text = '\\n'.join(current_chunk)\n",
    "        chunks.append(chunk_text)\n",
    "\n",
    "    # Join chunks with '<c>' separator\n",
    "    return '<c>'.join(chunks)\n",
    "\n",
    "# Create the chunks column\n",
    "df['chunks'] = df['raw_context'].apply(create_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c13d59f2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 615,
     "referenced_widgets": [
      "d0a95093530e4fc3a5f11bc9cbd1c5a4",
      "d6f8ce3191c84671be4f5dcc1adb703a",
      "841a55a84315476a83c406790c405df3",
      "1b1a61b152624ffd8415df06d19a80eb",
      "352b4c329e0841f798e0c81ca062607f",
      "611792bd796a4c41a496b1c1fbee751c",
      "ec441dd111bd444094efedb0e974ab48",
      "3af7c08c7c40401ba22c20375bc595f8",
      "f202454d9f8344ec9c175af8d7870d47",
      "eaa50630d72849bc8eebed94243bf355",
      "3fc67033c345471fbbfca0b32dbccef9",
      "7a8cdcbd19234e45a56e1992f5cd0770",
      "78d41bb260d64c92a338974955b47081",
      "973a9bda79a24110bcfa06928dd624d8",
      "a4fdd8378e7b4451ad2181bcca81f835",
      "1d295af551d34899bec8e5d7a48f5e6e",
      "0cc74cdc195740a7b6a521cd4ba37c11",
      "ecb3f87a5ff5485fadc1763e00e70aec",
      "bfdc4a6fc8534e65b93659729e37db90",
      "a7ae829da2984716be11dbe64bd07e13",
      "9de5a2f7db5b4c10af1e35971e5197b5",
      "e389c9ffe3454f148da787cf336f5fa8",
      "8d99baa20e0b480fb2117899bfbd2222",
      "5da7e86a6f314df3bd36d61dd5f3676f",
      "9131906b6cd34ad4b9e34710d877d47f",
      "0cad5c326f7048b0aeee3fb2ca0a2a60",
      "1ee53bdbd44e4a8b8f3eb0fa722059aa",
      "4cb642fcdd1242d0876c5d9e59769f19",
      "33085e168f7d43a99476512903c8483d",
      "d6f8f2235d374a838426a42e86b2bc3e",
      "9bf84dd8b7294235a2a323ed338882ae",
      "51f97a0a94ed472e98d2cb1f4dd2a316",
      "276450ab1ced46189125c672bf3effd0",
      "8375e10665e24ddfa660065e056da6ce",
      "794dc7ba8e534f89bec002a1f2253699",
      "e1e7fb1a444244019159607466ff0d99",
      "1db5ebaf482346908fc73eb1cb1db01c",
      "c482a53409c54ccc87223f84bb27af48",
      "6b41713f5556408ea1f362682ab1494e",
      "5a286d3b6705489eb080e129c6a7de58",
      "4797758b312845e0ac7a547605d1184c",
      "31d98e2b4a8e44e197cc37306c2c9d4d",
      "24b2c50405c74c769bbcd342f33df905",
      "91db908a54f44446bd644f69533f4c28",
      "368c1f180b424d9f990966e9a5d065fd",
      "caa49f5b053f42f59e87065e3943302c",
      "39b5869a853f4ef893f195c89dc601cb",
      "0157b13b6bcd4b38aa4419d0674096b5",
      "ac268620a75745b495bbaa55ce6fde80",
      "9abd7207949043669bc33a79e72972a9",
      "6f4d0e653409467c99e16c1ae2bd2e5e",
      "da47492dda374035ada126283b204393",
      "9e8da3c4621d495aabddd32e73548d61",
      "469e88cfb2b7421d8d366916b9c7067a",
      "cfd3b092c70641c49b0d357ab4f59872",
      "30a30da0d80040b2925990088a3bd20f",
      "6590dafe6c2541c08d377c4e89ba6060",
      "72a07e60b7cd43f0bc5c3d43dfcf7353",
      "2c78b76c5d1b42b8afbc8ce0ba2391ac",
      "46f17740259b468abcc5096f106b1cda",
      "4caa901ef7194d1697473fffb4b43bd5",
      "e991ec2eb138400b9f86c00b7749d990",
      "23c0ad606bab4d9fa86286cd3d7234fc",
      "3d14d60cb957446e86071bdcd44cf088",
      "8b1ce44ed2de4da4a640767844e39e04",
      "d44fe1775cf9414699d2dd388a6f894a",
      "dfd46efadf134d8982ec861883336740",
      "436fa04b7b094c9db66acf1c41a14f01",
      "2b0b41c3404f4944b2b2325c86bdc2f2",
      "d2e472eb10bf4b368558422b4c11c784",
      "6a5390914542474e8f5d37b903bbb5cc",
      "79ccddad3e3147c6a273de828cceb789",
      "656c8792fab7492593edced268095e51",
      "c67ac1e526a14a0490c8cd10fffc356b",
      "e1904f17f6214acabb3282eef0a7684e",
      "e46c9d75aa88407daeb381f24dc97f94",
      "4330e997404945b386680fee7f0ebccd",
      "900368265bd045f2bbcdfbd8a9895f21",
      "bbe4497064244c1687b2b8523d4b8f30",
      "3902b277c92e4095908d35cda0ff76ec",
      "57cae7c1fddd4709a830c66e05128ef1",
      "fdffbbb8669c47178c7f7ba38ff8354d",
      "1bdcf2c6f54047119e0d21c06e14ae27",
      "2c080d428dca45d093101012d025f018",
      "13d1b5392cd54e08b97b6f424d43fe2f",
      "7af14fc2f90f4d62943fc1453d356f81",
      "f9575eaa01964a28a392d6b86e121036",
      "87e5891ce940469c97c7193631c63c16",
      "f19c9db3c8ac4f08a4314bfda621439b",
      "d39d4ed14b3f47cb9d09e5dd02ef6f2b",
      "63a3654c07234a7ba4fe165a2d16e2f1",
      "7bb00f08f04d4c79925f7b4b97667cb2",
      "5d3a33f90dff4945a2db959053de8d17",
      "c2f798cd67d54337a9c6610328a496d1",
      "c9d48e50b9464fa4ba582f726817c2e7",
      "ea45942415b44ee1a11baeb2fdb9194d",
      "212b509b1ca148ea84c1a62e90fe0d74",
      "68a3aadf43674db99edab88d356a64e8",
      "62fc9a6e9c884edba771e69b7a240409",
      "4a3c608a1f6044639eb633dae104e0bd",
      "abdaf4e9b1df4b24a2153b4aadd1610f",
      "527612353f544d50a0fd1c6701c943ab",
      "142e310294e741db852fb0b708a10711",
      "dbc48a4318ae465089d727579b6bf9ae",
      "fe86b4a6be7948b28b2d39b6899275ba",
      "a23250ed855441a0b7e788354601821f",
      "7253ca85cbf04f0fb3f885dc7deddc51",
      "80a54bbf87294e05bf67462185896ee9",
      "e175c86f280d426b9806a66905c92afa",
      "1818242a211d4c71801ee4256a619b4a",
      "b875c8e4473b4c18b3f90965762b695e",
      "06b82056a2fa4fcba577ba0a03b89926",
      "ec777263a80646e7b382198c128d03d6",
      "f9b9fa59176f428b9dd1e0aeacbc93e1",
      "78a02368532f449e85885c503cfa96d4",
      "898a789aa32a46abb25029dc1545352f",
      "8617a1e2b0314dd59f03d44a1b4c7afe",
      "f5c811639b924f2f849c6a2faa2ce825",
      "86f12aca40184e5eb7529c4a9d84a080",
      "0bf68d5cfaab4d38b05b2edcaa320e00",
      "da09e76cdc6f432ca514b119f8870296"
     ]
    },
    "id": "c13d59f2",
    "outputId": "80f9e241-b543-40d7-967b-e3ad7a084d92"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1411879/3507626788.py:12: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  hf_embed_model = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL, model_kwargs={\"device\": \"cuda:0\"})\n",
      "2025-10-27 13:42:52.332373: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking if ChromaDB vectorstore already exists...\n",
      "‚ùå ChromaDB vectorstore not found. Creating new one...\n",
      "Processing documents and creating chunks...\n",
      "Total rows to process: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [00:00<00:00, 1981.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total chunks prepared: 500\n",
      "Average chunks per document: 1.00\n",
      "Creating new ChromaDB instance...\n",
      "Adding documents to ChromaDB...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding batches to ChromaDB: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Completed! Total time: 0.03 minutes\n",
      "Average processing rate: 273.3 documents per second\n",
      "ChromaDB created with 500 document chunks\n",
      "‚úÖ New ChromaDB vectorstore created successfully\n",
      "Final verification: ChromaDB collection contains 500 documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Configuration\n",
    "PERSIST_DIRECTORY = \"Input_Data/HotpotQA_dataset_test/chroma_db_all-MiniLM-L6-v2\"\n",
    "EMBEDDING_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "\n",
    "# Instantiate Hugging Face embeddings on cuda:0\n",
    "hf_embed_model = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL, model_kwargs={\"device\": \"cuda:0\"})\n",
    "\n",
    "def check_vectorstore_exists(persist_dir):\n",
    "    \"\"\"\n",
    "    Check if ChromaDB vectorstore already exists at the given directory\n",
    "    \"\"\"\n",
    "    if not os.path.exists(persist_dir):\n",
    "        return False\n",
    "\n",
    "    # Check if the directory contains ChromaDB files\n",
    "    chroma_files = ['chroma.sqlite3', 'index']\n",
    "    return any(os.path.exists(os.path.join(persist_dir, file)) for file in chroma_files)\n",
    "\n",
    "def load_existing_vectorstore(persist_dir, embedding_function):\n",
    "    \"\"\"\n",
    "    Load existing ChromaDB vectorstore\n",
    "    \"\"\"\n",
    "    print(f\"Loading existing ChromaDB from {persist_dir}...\")\n",
    "    vectorstore = Chroma(\n",
    "        embedding_function=embedding_function,\n",
    "        persist_directory=persist_dir\n",
    "    )\n",
    "\n",
    "    collection_count = vectorstore._collection.count()\n",
    "    print(f\"Loaded existing ChromaDB with {collection_count} documents\")\n",
    "    return vectorstore\n",
    "\n",
    "def create_new_vectorstore(df, persist_dir, embedding_function):\n",
    "    \"\"\"\n",
    "    Create new ChromaDB vectorstore from DataFrame\n",
    "    \"\"\"\n",
    "    # Prepare data for ChromaDB\n",
    "    documents = []\n",
    "    metadatas = []\n",
    "    ids = []\n",
    "\n",
    "    print(\"Processing documents and creating chunks...\")\n",
    "    print(f\"Total rows to process: {len(df)}\")\n",
    "\n",
    "    # Extract chunks and create documents with progress tracking\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing rows\"):\n",
    "        chunks = row['chunks'].split('<c>')\n",
    "\n",
    "        for chunk_idx, chunk in enumerate(chunks):\n",
    "            # Skip empty chunks\n",
    "            if chunk.strip():\n",
    "                documents.append(chunk.strip())\n",
    "\n",
    "                # Create metadata for each chunk\n",
    "                metadata = {\n",
    "                    'source_index': idx,\n",
    "                    'chunk_index': chunk_idx,\n",
    "                    'total_chunks': len(chunks),\n",
    "                    'token_count': count_tokens(chunk.strip())\n",
    "                }\n",
    "                metadatas.append(metadata)\n",
    "\n",
    "                # Create unique ID for each chunk\n",
    "                chunk_id = f\"doc_{idx}_chunk_{chunk_idx}\"\n",
    "                ids.append(chunk_id)\n",
    "\n",
    "    print(f\"\\nTotal chunks prepared: {len(documents)}\")\n",
    "    print(f\"Average chunks per document: {len(documents)/len(df):.2f}\")\n",
    "\n",
    "    # Create ChromaDB instance\n",
    "    print(\"Creating new ChromaDB instance...\")\n",
    "    vectorstore = Chroma(\n",
    "        embedding_function=embedding_function,\n",
    "        persist_directory=persist_dir\n",
    "    )\n",
    "\n",
    "    # Add documents to ChromaDB with progress tracking\n",
    "    print(\"Adding documents to ChromaDB...\")\n",
    "    batch_size = 100  # Process in batches to show progress and manage memory\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for i in tqdm(range(0, len(documents), batch_size), desc=\"Adding batches to ChromaDB\"):\n",
    "        end_idx = min(i + batch_size, len(documents))\n",
    "\n",
    "        batch_documents = documents[i:end_idx]\n",
    "        batch_metadatas = metadatas[i:end_idx]\n",
    "        batch_ids = ids[i:end_idx]\n",
    "\n",
    "        vectorstore.add_texts(\n",
    "            texts=batch_documents,\n",
    "            metadatas=batch_metadatas,\n",
    "            ids=batch_ids\n",
    "        )\n",
    "\n",
    "        # Optional: Print progress every few batches\n",
    "        if (i // batch_size + 1) % 10 == 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            processed = end_idx\n",
    "            rate = processed / elapsed\n",
    "            eta = (len(documents) - processed) / rate if rate > 0 else 0\n",
    "            print(f\"  Processed {processed}/{len(documents)} documents ({processed/len(documents)*100:.1f}%) | Rate: {rate:.1f} docs/sec | ETA: {eta/60:.1f} min\")\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"\\nCompleted! Total time: {total_time/60:.2f} minutes\")\n",
    "    print(f\"Average processing rate: {len(documents)/total_time:.1f} documents per second\")\n",
    "    print(f\"ChromaDB created with {len(documents)} document chunks\")\n",
    "\n",
    "    return vectorstore\n",
    "\n",
    "# Main execution logic\n",
    "print(\"Checking if ChromaDB vectorstore already exists...\")\n",
    "\n",
    "if check_vectorstore_exists(PERSIST_DIRECTORY):\n",
    "    # Load existing vectorstore\n",
    "    vectorstore = load_existing_vectorstore(PERSIST_DIRECTORY, hf_embed_model)\n",
    "    print(\"‚úÖ Using existing ChromaDB vectorstore\")\n",
    "\n",
    "else:\n",
    "    # Create new vectorstore\n",
    "    print(\"‚ùå ChromaDB vectorstore not found. Creating new one...\")\n",
    "    vectorstore = create_new_vectorstore(df, PERSIST_DIRECTORY, hf_embed_model)\n",
    "    print(\"‚úÖ New ChromaDB vectorstore created successfully\")\n",
    "\n",
    "# Optional: Verify the database\n",
    "collection_count = vectorstore._collection.count()\n",
    "print(f\"Final verification: ChromaDB collection contains {collection_count} documents\")\n",
    "\n",
    "# Optional: Add a force recreation option\n",
    "def recreate_vectorstore_if_needed(force_recreate=False):\n",
    "    \"\"\"\n",
    "    Utility function to force recreation of vectorstore if needed\n",
    "    \"\"\"\n",
    "    if force_recreate:\n",
    "        print(\"üîÑ Force recreation requested...\")\n",
    "        # Remove existing directory if it exists\n",
    "        if os.path.exists(PERSIST_DIRECTORY):\n",
    "            import shutil\n",
    "            shutil.rmtree(PERSIST_DIRECTORY)\n",
    "            print(f\"Removed existing vectorstore at {PERSIST_DIRECTORY}\")\n",
    "\n",
    "        # Create new vectorstore\n",
    "        return create_new_vectorstore(df, PERSIST_DIRECTORY, hf_embed_model)\n",
    "\n",
    "    return vectorstore\n",
    "\n",
    "# Uncomment the line below if you want to force recreation\n",
    "# vectorstore = recreate_vectorstore_if_needed(force_recreate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "Zt4Flul3yVTK",
   "metadata": {
    "id": "Zt4Flul3yVTK"
   },
   "outputs": [],
   "source": [
    "def retrieve_documents(query, vectorstore=vectorstore, k=3):\n",
    "    relevant_docs = vectorstore.similarity_search(query, k=k)\n",
    "    return relevant_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f706a677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "100b24ce",
   "metadata": {
    "id": "100b24ce"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93bef7a55e874fa790fbd0ec0681eb6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
    "hllm = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "22e9e8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 224.00 MiB. GPU 0 has a total capacity of 44.34 GiB of which 181.31 MiB is free. Process 295024 has 1.34 GiB memory in use. Process 696622 has 39.07 GiB memory in use. Including non-PyTorch memory, this process has 3.72 GiB memory in use. Of the allocated memory 3.39 GiB is allocated by PyTorch, and 25.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pipeline\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Create a pipeline for text-generation\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m hllm \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext-generation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/codecommit/.venv/lib/python3.10/site-packages/transformers/pipelines/__init__.py:1230\u001b[0m, in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, image_processor, processor, framework, revision, use_fast, token, device, device_map, dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m processor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1228\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprocessor\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m processor\n\u001b[0;32m-> 1230\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpipeline_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframework\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframework\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/codecommit/.venv/lib/python3.10/site-packages/transformers/pipelines/text_generation.py:121\u001b[0m, in \u001b[0;36mTextGenerationPipeline.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 121\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_model_type(\n\u001b[1;32m    123\u001b[0m         TF_MODEL_FOR_CAUSAL_LM_MAPPING_NAMES \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m MODEL_FOR_CAUSAL_LM_MAPPING_NAMES\n\u001b[1;32m    124\u001b[0m     )\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprefix\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preprocess_params:\n\u001b[1;32m    126\u001b[0m         \u001b[38;5;66;03m# This is very specific. The logic is quite complex and needs to be done\u001b[39;00m\n\u001b[1;32m    127\u001b[0m         \u001b[38;5;66;03m# as a \"default\".\u001b[39;00m\n\u001b[1;32m    128\u001b[0m         \u001b[38;5;66;03m# It also defines both some preprocess_kwargs and generate_kwargs\u001b[39;00m\n\u001b[1;32m    129\u001b[0m         \u001b[38;5;66;03m# which is why we cannot put them in their respective methods.\u001b[39;00m\n",
      "File \u001b[0;32m~/codecommit/.venv/lib/python3.10/site-packages/transformers/pipelines/base.py:1044\u001b[0m, in \u001b[0;36mPipeline.__init__\u001b[0;34m(self, model, tokenizer, feature_extractor, image_processor, processor, modelcard, framework, task, device, binary_output, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;66;03m# We shouldn't call `model.to()` for models loaded with accelerate as well as the case that model is already on device\u001b[39;00m\n\u001b[1;32m   1038\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1039\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1040\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m   1041\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m   1042\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m hf_device_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1043\u001b[0m ):\n\u001b[0;32m-> 1044\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1046\u001b[0m \u001b[38;5;66;03m# If it's a generation pipeline and the model can generate:\u001b[39;00m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;66;03m# 1 - create a local generation config. This is done to avoid side-effects on the model as we apply local\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;66;03m# tweaks to the generation config.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;66;03m# 2 - load the assistant model if it is passed.\u001b[39;00m\n\u001b[1;32m   1050\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pipeline_calls_generate \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mcan_generate():\n",
      "File \u001b[0;32m~/codecommit/.venv/lib/python3.10/site-packages/transformers/modeling_utils.py:4462\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   4457\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_present_in_args:\n\u001b[1;32m   4458\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   4459\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4460\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `dtype` by passing the correct `dtype` argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4461\u001b[0m         )\n\u001b[0;32m-> 4462\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/codecommit/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1369\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1366\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1367\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1369\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/codecommit/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:928\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    927\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 928\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    931\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    932\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    933\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    938\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    939\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/codecommit/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:928\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    927\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 928\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    931\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    932\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    933\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    938\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    939\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 928 (2 times)]\u001b[0m\n",
      "File \u001b[0;32m~/codecommit/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:928\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    927\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 928\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    931\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    932\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    933\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    938\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    939\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/codecommit/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:955\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    951\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    952\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    953\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    954\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 955\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    956\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    958\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_subclasses\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfake_tensor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FakeTensor\n",
      "File \u001b[0;32m~/codecommit/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1355\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1349\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1350\u001b[0m             device,\n\u001b[1;32m   1351\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1352\u001b[0m             non_blocking,\n\u001b[1;32m   1353\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1354\u001b[0m         )\n\u001b[0;32m-> 1355\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1356\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1357\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1358\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1359\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1360\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1361\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 224.00 MiB. GPU 0 has a total capacity of 44.34 GiB of which 181.31 MiB is free. Process 295024 has 1.34 GiB memory in use. Process 696622 has 39.07 GiB memory in use. Including non-PyTorch memory, this process has 3.72 GiB memory in use. Of the allocated memory 3.39 GiB is allocated by PyTorch, and 25.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Create a pipeline for text-generation\n",
    "hllm = pipeline(\"text-generation\", model=hllm, tokenizer=tokenizer,pad_token_id=tokenizer.eos_token_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "karIyZTCKZrs",
   "metadata": {
    "id": "karIyZTCKZrs"
   },
   "outputs": [],
   "source": [
    "def route_question(query, hllm):\n",
    "    \n",
    "    # Compose the prompt as a single string (no chat format)\n",
    "    prompt = f\"\"\"You are a question classifier. Your job is to analyze the question and classify it into one of the following three categories:\n",
    "\n",
    "LLM ‚Äì If the question can be answered using general knowledge the LLM has been trained on, without needing retrieval.\n",
    "\n",
    "Single-hop ‚Äì If the answer requires retrieving a single fact or document to answer.\n",
    "\n",
    "Multi-hop ‚Äì If the answer requires combining multiple pieces of information retrieved from different documents or sources.\n",
    "\n",
    "Return only one of the three labels: LLM, Single-hop, or Multi-hop.\n",
    "\n",
    "Examples:\n",
    "Question: What is the capital of France?\n",
    "Answer: LLM\n",
    "\n",
    "Question: Who is the CEO of OpenAI?\n",
    "Answer: LLM\n",
    "\n",
    "Question: What is the average temperature in Berlin in June?\n",
    "Answer: Single-hop\n",
    "\n",
    "Question: When was the iPhone 12 released and how did its sales compare to the iPhone 11?\n",
    "Answer: Multi-hop\n",
    "\n",
    "Question: What is the boiling point of water at sea level?\n",
    "Answer: LLM\n",
    "\n",
    "Question: What are the side effects of ibuprofen?\n",
    "Answer: Single-hop\n",
    "\n",
    "Question: Compare the GDP of Germany and France in 2023.\n",
    "Answer: Multi-hop\n",
    "\n",
    "Question: What year did World War II end?\n",
    "Answer: LLM\n",
    "\n",
    "Question: Who won the best actor Oscar in 2024 and what movie were they in?\n",
    "Answer: Multi-hop\n",
    "\n",
    "Question: How many calories are in a McDonald's Big Mac?\n",
    "Answer: Single-hop\n",
    "\n",
    "Now classify the following question:\n",
    "Question: {query}\n",
    "Answer:\"\"\"\n",
    "\n",
    "    # Generate the classification\n",
    "    output = hllm(prompt, max_new_tokens=100, do_sample=False)[0]['generated_text']\n",
    "\n",
    "    # Extract only the answer label (last line after \"Answer:\")\n",
    "    answer = output.split(\"Answer:\")[-1].strip().split(\"\\n\")[0]\n",
    "    answer = answer.replace('\"', '').replace(\"'\", \"\")\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "300259eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load model directly\n",
    "# from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# # tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-3B\")\n",
    "# # llm = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2.5-3B\")\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-3B\",device_map = 'cuda:0')\n",
    "# llm = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-3.2-3B\",device_map = 'cuda:0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fcc480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d42bc898b4eb4019888610629526088c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 252.00 MiB. GPU 0 has a total capacity of 44.34 GiB of which 181.31 MiB is free. Process 295024 has 1.34 GiB memory in use. Process 696622 has 39.07 GiB memory in use. Including non-PyTorch memory, this process has 3.72 GiB memory in use. Of the allocated memory 3.39 GiB is allocated by PyTorch, and 25.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Load model and tokenizer\u001b[39;00m\n\u001b[1;32m      3\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgoogle/flan-t5-xl\u001b[39m\u001b[38;5;124m\"\u001b[39m,device_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForSeq2SeqLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgoogle/flan-t5-xl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/codecommit/.venv/lib/python3.10/site-packages/transformers/modeling_utils.py:4462\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   4457\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_present_in_args:\n\u001b[1;32m   4458\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   4459\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4460\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `dtype` by passing the correct `dtype` argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4461\u001b[0m         )\n\u001b[0;32m-> 4462\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/codecommit/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1369\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1366\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1367\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1369\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/codecommit/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:928\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    927\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 928\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    931\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    932\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    933\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    938\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    939\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/codecommit/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:955\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    951\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    952\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    953\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    954\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 955\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    956\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    958\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_subclasses\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfake_tensor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FakeTensor\n",
      "File \u001b[0;32m~/codecommit/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1355\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1349\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1350\u001b[0m             device,\n\u001b[1;32m   1351\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1352\u001b[0m             non_blocking,\n\u001b[1;32m   1353\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1354\u001b[0m         )\n\u001b[0;32m-> 1355\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1356\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1357\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1358\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1359\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1360\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1361\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 252.00 MiB. GPU 0 has a total capacity of 44.34 GiB of which 181.31 MiB is free. Process 295024 has 1.34 GiB memory in use. Process 696622 has 39.07 GiB memory in use. Including non-PyTorch memory, this process has 3.72 GiB memory in use. Of the allocated memory 3.39 GiB is allocated by PyTorch, and 25.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# Load model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-xl\",device_map='cuda:1')\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-xl\").to('cuda:1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aAIrXYAukKBr",
   "metadata": {
    "id": "aAIrXYAukKBr"
   },
   "outputs": [],
   "source": [
    "def answer_generator_direct(query):\n",
    "    # Use the globally loaded tokenizer and llm\n",
    "    # Prepare the prompt for the model\n",
    "    prompt = f\"User question: {query}\\n Answer:\"\n",
    "\n",
    "    # Tokenize and generate, passing attention_mask for reliable results\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    input_ids = inputs.input_ids.to(\"cuda:0\")\n",
    "    attention_mask = inputs.attention_mask.to(\"cuda:0\")\n",
    "\n",
    "    pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "    output_ids = llm.generate(input_ids, attention_mask=attention_mask, pad_token_id=pad_token_id)\n",
    "    output = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    # Extract only the answer after \"Answer:\"\n",
    "    if \"Answer:\" in output:\n",
    "        answer = output.split(\"Answer:\")[-1].strip().split(\"\\n\")[0]\n",
    "    else:\n",
    "        answer = output.strip().split(\"\\n\")[-1]\n",
    "    answer = answer.replace('\"', '').replace(\"'\", \"\")\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "lGxreYhFp8fe",
   "metadata": {
    "id": "lGxreYhFp8fe"
   },
   "outputs": [],
   "source": [
    "def answer_generator_single_hop(query, context):\n",
    "    # Use the globally loaded tokenizer and llm from file_context_1\n",
    "    # Prepare the prompt for the model\n",
    "    prompt = (\n",
    "        \"You are an expert at answering the question just based on the context. \"\n",
    "        \"Given the context, answer the user question. If you cannot answer the question based on context, \"\n",
    "        \"state properly that you cannot answer the question.\\n\\n\"\n",
    "        f\"Context:\\n{context}\\n\\nUser question: {query}\\nAnswer:\"\n",
    "    )\n",
    "\n",
    "    # Tokenize and generate, passing attention_mask for reliable results\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    input_ids = inputs.input_ids.to(\"cuda:0\")\n",
    "    attention_mask = inputs.attention_mask.to(\"cuda:0\")\n",
    "\n",
    "    pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "    output_ids = llm.generate(input_ids, attention_mask=attention_mask, pad_token_id=pad_token_id)\n",
    "    output = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    # Extract only the answer after \"Answer:\"\n",
    "    if \"Answer:\" in output:\n",
    "        answer = output.split(\"Answer:\")[-1].strip().split(\"\\n\")[0]\n",
    "    else:\n",
    "        answer = output.strip().split(\"\\n\")[-1]\n",
    "    answer = answer.replace('\"', '').replace(\"'\", \"\")\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "iaiGniBgdxZW",
   "metadata": {
    "id": "iaiGniBgdxZW"
   },
   "outputs": [],
   "source": [
    "def chain_of_thought_retriever(query, vectorstore, answer_generator_func, max_iterations=3, k=3):\n",
    "\n",
    "    def create_cot_prompt(query, context):\n",
    "        return (\n",
    "            \"You are an expert at step-by-step reasoning. \"\n",
    "            \"Answer the following question by reasoning step-by-step based on the provided context.Strictly follow the instructions please.\\n\\n\"\n",
    "            f\"Context:\\n{context}\\n\\n\"\n",
    "            f\"Question: {query}\\n\\n\"\n",
    "            \"Instructions:\\n\"\n",
    "            \"1. Break down the question into logical steps\\n\"\n",
    "            \"2. Use the context to find relevant information for each step\\n\"\n",
    "            \"3. Reason through each step systematically\\n\"\n",
    "            \"4. If you can provide a complete answer, conclude with \\\"So the answer is: [your answer]\\\"\\n\"\n",
    "            \"5. If you need more information to answer completely, state what additional information is needed and provide your current reasoning\\n\\n\"\n",
    "            \"Answer by reasoning step-by-step:\"\n",
    "        )\n",
    "\n",
    "    def extract_reasoning_and_check_completeness(response):\n",
    "        response = response.strip()\n",
    "        \n",
    "        # Check for the complete answer pattern\n",
    "        if \"So the answer is:\" in response:\n",
    "            answer_part = response.split(\"So the answer is:\")[-1].strip()\n",
    "            return {\n",
    "                \"complete\": True,\n",
    "                \"answer\": answer_part,\n",
    "                \"reasoning\": response\n",
    "            }\n",
    "        \n",
    "        # If response is very short and seems like a direct answer, treat as complete\n",
    "        response_lower = response.lower()\n",
    "        if (len(response.split()) <= 5 and \n",
    "            not any(phrase in response_lower for phrase in [\n",
    "                \"need more information\", \"cannot determine\", \"missing\", \n",
    "                \"unclear\", \"require\", \"cannot find\", \"not enough\", \n",
    "                \"insufficient\", \"unable to\", \"more details\"\n",
    "            ])):\n",
    "            # This looks like a direct answer, format it properly\n",
    "            return {\n",
    "                \"complete\": True,\n",
    "                \"answer\": response,\n",
    "                \"reasoning\": f\"Based on the context provided, the answer is: {response}. So the answer is: {response}\"\n",
    "            }\n",
    "        \n",
    "        # Otherwise, it's incomplete\n",
    "        return {\n",
    "            \"complete\": False,\n",
    "            \"answer\": None,\n",
    "            \"reasoning\": response\n",
    "        }\n",
    "\n",
    "    def generate_follow_up_query(reasoning, original_query):\n",
    "        reasoning_lower = reasoning.lower()\n",
    "        # Look for phrases indicating missing information\n",
    "        if any(phrase in reasoning_lower for phrase in [\"need more information\", \"cannot determine\", \"missing\", \"unclear\", \"require\", \"cannot find\"]):\n",
    "            lines = reasoning.split('\\n')\n",
    "            for line in lines:\n",
    "                if any(phrase in line.lower() for phrase in [\"need\", \"require\", \"missing\", \"unclear\", \"cannot find\"]):\n",
    "                    words = line.split()\n",
    "                    key_terms = [word.strip('.,?!') for word in words if len(word) > 3 and word.isalpha()]\n",
    "                    if key_terms:\n",
    "                        return \" \".join(key_terms[:5])\n",
    "        # Fallback: extract key entities from original query\n",
    "        query_words = original_query.split()\n",
    "        return \" \".join([word for word in query_words if len(word) > 3])[:100]\n",
    "\n",
    "    all_contexts = []\n",
    "    reasoning_steps = []\n",
    "    iteration_details = []\n",
    "    current_query = query\n",
    "\n",
    "    for iteration in range(1, max_iterations + 1):\n",
    "        try:\n",
    "            relevant_docs = vectorstore.similarity_search(current_query, k=k)\n",
    "            current_context = \"\\n\\n\".join([\n",
    "                f\"Document {i+1}:\\n{doc.page_content}\"\n",
    "                for i, doc in enumerate(relevant_docs)\n",
    "            ])\n",
    "            all_contexts.append({\n",
    "                \"iteration\": iteration,\n",
    "                \"query\": current_query,\n",
    "                \"context\": current_context,\n",
    "                \"num_docs\": len(relevant_docs)\n",
    "            })\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"success\": False,\n",
    "                \"error\": f\"Document retrieval failed at iteration {iteration}: {e}\",\n",
    "                \"final_answer\": None,\n",
    "                \"reasoning_steps\": reasoning_steps,\n",
    "                \"iteration_details\": iteration_details,\n",
    "                \"all_contexts\": all_contexts\n",
    "            }\n",
    "\n",
    "        # Step 2: Create CoT prompt and generate reasoning\n",
    "        cot_prompt = create_cot_prompt(query, current_context)\n",
    "        try:\n",
    "            reasoning_response = answer_generator_func(cot_prompt, current_context)  # Pass the cot_prompt, not original query\n",
    "            reasoning_steps.append({\n",
    "                \"iteration\": iteration,\n",
    "                \"query\": current_query,\n",
    "                \"reasoning\": reasoning_response\n",
    "            })\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"success\": False,\n",
    "                \"error\": f\"Reasoning generation failed at iteration {iteration}: {e}\",\n",
    "                \"final_answer\": None,\n",
    "                \"reasoning_steps\": reasoning_steps,\n",
    "                \"iteration_details\": iteration_details,\n",
    "                \"all_contexts\": all_contexts\n",
    "            }\n",
    "\n",
    "        # Step 3: Check if reasoning is complete\n",
    "        result = extract_reasoning_and_check_completeness(reasoning_response)\n",
    "        iteration_details.append({\n",
    "            \"iteration\": iteration,\n",
    "            \"query\": current_query,\n",
    "            \"num_docs_retrieved\": len(relevant_docs),\n",
    "            \"reasoning_complete\": result[\"complete\"],\n",
    "            \"reasoning_length\": len(reasoning_response)\n",
    "        })\n",
    "\n",
    "        if result[\"complete\"]:\n",
    "            return {\n",
    "                \"success\": True,\n",
    "                \"final_answer\": result[\"answer\"],\n",
    "                \"complete_reasoning\": result[\"reasoning\"],\n",
    "                \"iterations_used\": iteration,\n",
    "                \"reasoning_steps\": reasoning_steps,\n",
    "                \"iteration_details\": iteration_details,\n",
    "                \"all_contexts\": all_contexts\n",
    "            }\n",
    "\n",
    "        # Step 4: Generate follow-up query for next iteration\n",
    "        if iteration < max_iterations:\n",
    "            current_query = generate_follow_up_query(reasoning_response, query)\n",
    "\n",
    "    # Return incomplete result\n",
    "    return {\n",
    "        \"success\": False,\n",
    "        \"final_answer\": None,\n",
    "        \"error\": f\"Could not generate complete answer within {max_iterations} iterations\",\n",
    "        \"last_reasoning\": reasoning_steps[-1][\"reasoning\"] if reasoning_steps else None,\n",
    "        \"iterations_used\": max_iterations,\n",
    "        \"reasoning_steps\": reasoning_steps,\n",
    "        \"iteration_details\": iteration_details,\n",
    "        \"all_contexts\": all_contexts\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8fc00dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_generator_multi_hop(query, vectorstore, answer_generator, k=3):\n",
    "\n",
    "    cot_result = chain_of_thought_retriever(\n",
    "        query=query,\n",
    "        vectorstore=vectorstore,\n",
    "        answer_generator_func=answer_generator,\n",
    "        max_iterations=3,\n",
    "        k=k\n",
    "    )\n",
    "\n",
    "    all_documents = []\n",
    "    for context_info in cot_result.get('all_contexts', []):\n",
    "        all_documents.append({\n",
    "            \"iteration\": context_info['iteration'],\n",
    "            \"content\": context_info['context'],\n",
    "            \"query_used\": context_info['query']\n",
    "        })\n",
    "\n",
    "    return {\n",
    "        \"documents\": all_documents,\n",
    "        \"cot_result\": cot_result,\n",
    "        \"final_answer\": cot_result.get('final_answer'),\n",
    "        \"success\": cot_result.get('success', False)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "_uTFYbfQdxcq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_uTFYbfQdxcq",
    "outputId": "8b69e0c1-db06-4247-ee2a-55ec79eb767f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: None\n"
     ]
    }
   ],
   "source": [
    "result = answer_generator_multi_hop(\n",
    "    query=\"\"\"The Oberoi family is part of a hotel company that has a head office in what city?\"\"\",\n",
    "    vectorstore=vectorstore,\n",
    "    answer_generator=answer_generator_single_hop,\n",
    "    k=1\n",
    ")\n",
    "\n",
    "if result['success']:\n",
    "    print(f\"Answer: {result['final_answer']}\")\n",
    "else:\n",
    "    print(\"Could not find complete answer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "qvEV3ADSeqiu",
   "metadata": {
    "id": "qvEV3ADSeqiu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ztfncYfmUlOA",
   "metadata": {
    "id": "ztfncYfmUlOA"
   },
   "outputs": [],
   "source": [
    "from typing import Dict, Any, List, Union\n",
    "from langgraph.graph import StateGraph, END\n",
    "from typing_extensions import TypedDict\n",
    "from langchain.schema import Document\n",
    "\n",
    "# Define the state that will be passed between nodes\n",
    "class RoutingRAGState(TypedDict):\n",
    "    question: str\n",
    "    original_question: str\n",
    "    routing_result: str\n",
    "    answer: str\n",
    "    answer_type: str  # \"direct\", \"single-hop\", or \"multi-hop\"\n",
    "    # Metadata for tracking the path taken\n",
    "    path_taken: List[str]\n",
    "    error_message: str\n",
    "    context_docs: List[Document]\n",
    "\n",
    "def create_routing_rag_graph(\n",
    "    vectorstore,\n",
    "    router_llm,\n",
    "    answer_generation_direct,\n",
    "    answer_generation_single_hop,\n",
    "    answer_generation_multi_hop,\n",
    "    route_question,\n",
    "    k: int = 3\n",
    "):\n",
    "    \n",
    "    def route_question_node(state: RoutingRAGState) -> RoutingRAGState:\n",
    "\n",
    "        try:\n",
    "            routing_decision = route_question(state[\"question\"], router_llm)\n",
    "\n",
    "            return {\n",
    "                **state,\n",
    "                \"routing_result\": routing_decision,\n",
    "                \"path_taken\": state[\"path_taken\"] + [f\"route_question -> {routing_decision}\"]\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                **state,\n",
    "                \"routing_result\": \"single-hop\",  # Default fallback\n",
    "                \"error_message\": f\"Routing error: {e}\",\n",
    "                \"path_taken\": state[\"path_taken\"] + [\"route_question -> error_fallback\"]\n",
    "            }\n",
    "\n",
    "    def answer_generation_direct_node(state: RoutingRAGState) -> RoutingRAGState:\n",
    "\n",
    "        try:\n",
    "            answer = answer_generation_direct(state[\"question\"])\n",
    "            print(f\"‚úÖ Direct answer generated: {answer}...\")\n",
    "\n",
    "            return {\n",
    "                **state,\n",
    "                \"answer\": answer,\n",
    "                \"answer_type\": \"direct\",\n",
    "                \"path_taken\": state[\"path_taken\"] + [\"answer_generation_direct\"]\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                **state,\n",
    "                \"answer\": f\"I apologize, but I encountered an error generating a direct answer: {e}\",\n",
    "                \"answer_type\": \"direct_error\",\n",
    "                \"error_message\": f\"Direct answer error: {e}\",\n",
    "                \"path_taken\": state[\"path_taken\"] + [\"answer_generation_direct -> error\"]\n",
    "            }\n",
    "\n",
    "    def answer_generation_single_hop_node(state: RoutingRAGState) -> RoutingRAGState:\n",
    "\n",
    "        try:\n",
    "            context = vectorstore.similarity_search(state[\"question\"], k=3)\n",
    "            answer = answer_generation_single_hop(state[\"question\"], context)\n",
    "\n",
    "            return {\n",
    "                **state,\n",
    "                \"answer\": answer,\n",
    "                \"answer_type\": \"single-hop\",\n",
    "                \"context_docs\": context,\n",
    "                \"path_taken\": state[\"path_taken\"] + [\"answer_generation_single_hop\"]\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                **state,\n",
    "                \"answer\": f\"I apologize, but I encountered an error during single-hop retrieval: {e}\",\n",
    "                \"answer_type\": \"single-hop_error\",\n",
    "                \"error_message\": f\"Single-hop error: {e}\",\n",
    "                \"path_taken\": state[\"path_taken\"] + [\"answer_generation_single_hop -> error\"]\n",
    "            }\n",
    "\n",
    "    def answer_generation_multi_hop_node(state: RoutingRAGState) -> RoutingRAGState:\n",
    "        \"\"\"Generate answer using your existing multi-hop function\"\"\"\n",
    "\n",
    "        try:\n",
    "            result = answer_generation_multi_hop(state[\"question\"], vectorstore, answer_generator_single_hop, k)\n",
    "\n",
    "            return {\n",
    "                **state,\n",
    "                \"answer\": result['final_answer'],\n",
    "                \"answer_type\": \"multi-hop\",\n",
    "                \"context_docs\": result['documents'], \n",
    "                \"path_taken\": state[\"path_taken\"] + [\"answer_generation_multi_hop\"]\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                **state,\n",
    "                \"answer\": f\"I apologize, but I encountered an error during multi-hop retrieval: {e}\",\n",
    "                \"answer_type\": \"multi-hop_error\",\n",
    "                \"error_message\": f\"Multi-hop error: {e}\",\n",
    "                \"path_taken\": state[\"path_taken\"] + [\"answer_generation_multi_hop -> error\"]\n",
    "            }\n",
    "\n",
    "    def final_answer_node(state: RoutingRAGState) -> RoutingRAGState:\n",
    "\n",
    "        if state.get('error_message'):\n",
    "            print(f\"‚ö†Ô∏è Warnings: {state['error_message']}\")\n",
    "\n",
    "        return {\n",
    "            **state,\n",
    "            \"path_taken\": state[\"path_taken\"] + [\"final_answer\"]\n",
    "        }\n",
    "\n",
    "    # Conditional routing function\n",
    "    def decide_answer_generation_strategy(state: RoutingRAGState) -> str:\n",
    "        \"\"\"Route to appropriate answer generation strategy based on routing result\"\"\"\n",
    "        routing_result = state[\"routing_result\"].lower()\n",
    "\n",
    "        if \"llm\" in routing_result:\n",
    "            return \"answer_generation_direct\"\n",
    "        elif \"single-hop\" in routing_result or \"single\" in routing_result:\n",
    "            return \"answer_generation_single_hop\"\n",
    "        else:  # multi-hop or any other case\n",
    "            return \"answer_generation_multi_hop\"\n",
    "\n",
    "    # Build the graph\n",
    "    workflow = StateGraph(RoutingRAGState)\n",
    "\n",
    "    # Add nodes\n",
    "    workflow.add_node(\"route_question\", route_question_node)\n",
    "    workflow.add_node(\"answer_generation_direct\", answer_generation_direct_node)\n",
    "    workflow.add_node(\"answer_generation_single_hop\", answer_generation_single_hop_node)\n",
    "    workflow.add_node(\"answer_generation_multi_hop\", answer_generation_multi_hop_node)\n",
    "    workflow.add_node(\"final_answer\", final_answer_node)\n",
    "\n",
    "    # Set entry point\n",
    "    workflow.set_entry_point(\"route_question\")\n",
    "\n",
    "    # Add conditional edge from routing to answer generation\n",
    "    workflow.add_conditional_edges(\n",
    "        \"route_question\",\n",
    "        decide_answer_generation_strategy,\n",
    "        {\n",
    "            \"answer_generation_direct\": \"answer_generation_direct\",\n",
    "            \"answer_generation_single_hop\": \"answer_generation_single_hop\",\n",
    "            \"answer_generation_multi_hop\": \"answer_generation_multi_hop\"\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # All answer generation nodes lead to final answer\n",
    "    workflow.add_edge(\"answer_generation_direct\", \"final_answer\")\n",
    "    workflow.add_edge(\"answer_generation_single_hop\", \"final_answer\")\n",
    "    workflow.add_edge(\"answer_generation_multi_hop\", \"final_answer\")\n",
    "\n",
    "    # Terminal node\n",
    "    workflow.add_edge(\"final_answer\", END)\n",
    "\n",
    "    return workflow.compile()\n",
    "\n",
    "\n",
    "def run_routing_rag_workflow(\n",
    "    question: str,\n",
    "    compiled_graph\n",
    ") -> Dict[str, Any]:\n",
    "\n",
    "    initial_state = RoutingRAGState(\n",
    "        question=question,\n",
    "        original_question=question,\n",
    "        routing_result=\"\",\n",
    "        answer=\"\",\n",
    "        answer_type=\"\",\n",
    "        path_taken=[],\n",
    "        error_message=\"\",\n",
    "        context_docs=[]\n",
    "    )\n",
    "\n",
    "    final_state = compiled_graph.invoke(initial_state)\n",
    "\n",
    "    return final_state\n",
    "\n",
    "\n",
    "def setup_and_run_routing_rag(\n",
    "    question: str,\n",
    "    vectorstore,\n",
    "    router_llm,\n",
    "    answer_generation_direct,\n",
    "    answer_generation_single_hop,\n",
    "    answer_generation_multi_hop,\n",
    "    route_question,\n",
    "    k: int = 3\n",
    "):\n",
    "    \n",
    "    compiled_graph = create_routing_rag_graph(\n",
    "        vectorstore=vectorstore,\n",
    "        router_llm=router_llm,\n",
    "        answer_generation_direct=answer_generation_direct,\n",
    "        answer_generation_single_hop=answer_generation_single_hop,\n",
    "        answer_generation_multi_hop=answer_generation_multi_hop,\n",
    "        route_question=route_question,\n",
    "        k=k\n",
    "    )\n",
    "\n",
    "    result = run_routing_rag_workflow(question, compiled_graph)\n",
    "\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "Ony_1F4fBwOH",
   "metadata": {
    "id": "Ony_1F4fBwOH"
   },
   "outputs": [],
   "source": [
    "def main(question):\n",
    "\n",
    "    result = setup_and_run_routing_rag(\n",
    "        question=question,\n",
    "        vectorstore=vectorstore,\n",
    "        router_llm=hllm,\n",
    "        answer_generation_direct=answer_generator_direct,\n",
    "        answer_generation_single_hop=answer_generator_single_hop,\n",
    "        answer_generation_multi_hop=answer_generator_multi_hop,\n",
    "        route_question=route_question,\n",
    "        k=3\n",
    "    )\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bafc517",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "247c00a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing questions:   0%|          | 0/10 [00:00<?, ?it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Processing questions:  10%|‚ñà         | 1/10 [00:17<02:34, 17.19s/it]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Processing questions:  20%|‚ñà‚ñà        | 2/10 [00:20<01:11,  8.91s/it]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Processing questions:  30%|‚ñà‚ñà‚ñà       | 3/10 [00:35<01:22, 11.84s/it]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Processing questions:  40%|‚ñà‚ñà‚ñà‚ñà      | 4/10 [00:38<00:50,  8.46s/it]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Processing questions:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 5/10 [00:54<00:54, 10.99s/it]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Processing questions:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 6/10 [00:56<00:31,  7.85s/it]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Direct answer generated: Portland State University and Boston University are both research institutions. Portland State University is a public research university in...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing questions:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 7/10 [00:59<00:19,  6.36s/it]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Processing questions:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 8/10 [01:15<00:18,  9.41s/it]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Processing questions:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 9/10 [01:25<00:09,  9.61s/it]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Processing questions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [01:35<00:00,  9.60s/it]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "answers = []\n",
    "paths = []\n",
    "contexts = []\n",
    "times = []\n",
    "\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing questions\"):\n",
    "    question = row['question']\n",
    "    stime = time.time()\n",
    "    result = main(question)\n",
    "    times.append(time.time() - stime)\n",
    "    answers.append(result.get('answer', None))\n",
    "    paths.append(result.get('path_taken', None))\n",
    "    contexts.append(result.get('context_docs', None))\n",
    "\n",
    "df['predicted_answer'] = answers\n",
    "df['path_taken'] = paths\n",
    "df['retrieved_context'] = contexts\n",
    "df['time'] = times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "98fc94df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>answer</th>\n",
       "      <th>predicted_answer</th>\n",
       "      <th>path_taken</th>\n",
       "      <th>retrieved_context</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jared Leto is an American entertainer, who has...</td>\n",
       "      <td>[['Hurricane (Thirty Seconds to Mars song)', [...</td>\n",
       "      <td>Steve Roland \"Pre\" Prefontaine</td>\n",
       "      <td>Steve Prefontaine</td>\n",
       "      <td>[route_question -&gt; Multi-hop, answer_generatio...</td>\n",
       "      <td>[{'iteration': 1, 'content': 'Document 1:\n",
       "Hurr...</td>\n",
       "      <td>17.189109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ESPN College Football Friday Primetime is prec...</td>\n",
       "      <td>[['Derek Carr', ['Derek Dallas Carr (born Marc...</td>\n",
       "      <td>Daniel Kanell</td>\n",
       "      <td>Tim Hasselbeck</td>\n",
       "      <td>[route_question -&gt; Single-hop, answer_generati...</td>\n",
       "      <td>[page_content='Derek Carr Derek Dallas Carr (b...</td>\n",
       "      <td>3.111104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This Serbian-American inventor was a person yo...</td>\n",
       "      <td>[['Recluse', ['A recluse is a person who lives...</td>\n",
       "      <td>the public and society</td>\n",
       "      <td>Nikola Tesla</td>\n",
       "      <td>[route_question -&gt; Multi-hop, answer_generatio...</td>\n",
       "      <td>[{'iteration': 1, 'content': 'Document 1:\n",
       "Recl...</td>\n",
       "      <td>15.325993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>When was the movie adaption of Jennifer Weiner...</td>\n",
       "      <td>[['Jennifer Weiner', ['Jennifer Weiner (born M...</td>\n",
       "      <td>2005</td>\n",
       "      <td>In Her Shoes is a 2005 American comedy-drama f...</td>\n",
       "      <td>[route_question -&gt; Single-hop, answer_generati...</td>\n",
       "      <td>[page_content='Jennifer Weiner Jennifer Weiner...</td>\n",
       "      <td>3.269786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Operation Hedge-hop was a military plan develo...</td>\n",
       "      <td>[['McDonnell FH Phantom', ['The McDonnell FH P...</td>\n",
       "      <td>United States Army Air Forces (USAAF)</td>\n",
       "      <td>None</td>\n",
       "      <td>[route_question -&gt; Multi-hop, answer_generatio...</td>\n",
       "      <td>[{'iteration': 1, 'content': 'Document 1:\n",
       "McDo...</td>\n",
       "      <td>15.491253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Portland State University and Boston Universit...</td>\n",
       "      <td>[['Portland State University', ['Portland Stat...</td>\n",
       "      <td>yes</td>\n",
       "      <td>Portland State University and Boston Universit...</td>\n",
       "      <td>[route_question -&gt; LLM (Yes, both Portland Sta...</td>\n",
       "      <td>[]</td>\n",
       "      <td>1.758760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Agent Provocateur contained the biggest single...</td>\n",
       "      <td>[['Robert Poley', ['Robert Poley, or Pooley (f...</td>\n",
       "      <td>November 1984</td>\n",
       "      <td>November</td>\n",
       "      <td>[route_question -&gt; Single-hop, answer_generati...</td>\n",
       "      <td>[page_content='Robert Poley Robert Poley, or P...</td>\n",
       "      <td>3.287352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What class was 6029,a four-cylinder, simple, n...</td>\n",
       "      <td>[['Hunter Valley Mining Locomotives', ['Hunter...</td>\n",
       "      <td>The AD60 class</td>\n",
       "      <td>None</td>\n",
       "      <td>[route_question -&gt; Multi-hop, answer_generatio...</td>\n",
       "      <td>[{'iteration': 1, 'content': 'Document 1:\n",
       "Hunt...</td>\n",
       "      <td>15.941521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The 2003 Major League Soccer All-Star Game was...</td>\n",
       "      <td>[['2010 MLS All-Star Game', ['The 2010 Major L...</td>\n",
       "      <td>StubHub Center</td>\n",
       "      <td>StubHub Center</td>\n",
       "      <td>[route_question -&gt; Multi-hop, answer_generatio...</td>\n",
       "      <td>[{'iteration': 1, 'content': 'Document 1:\n",
       "2010...</td>\n",
       "      <td>10.040618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The GUID Partition Table forms a part of which...</td>\n",
       "      <td>[['Volume Table of Contents', ['In the IBM mai...</td>\n",
       "      <td>Unified Extensible Firmware Interface</td>\n",
       "      <td>Unified Extensible Firmware Interface (UEFI)</td>\n",
       "      <td>[route_question -&gt; Multi-hop, answer_generatio...</td>\n",
       "      <td>[{'iteration': 1, 'content': 'Document 1:\n",
       "Volu...</td>\n",
       "      <td>10.536506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  Jared Leto is an American entertainer, who has...   \n",
       "1  ESPN College Football Friday Primetime is prec...   \n",
       "2  This Serbian-American inventor was a person yo...   \n",
       "3  When was the movie adaption of Jennifer Weiner...   \n",
       "4  Operation Hedge-hop was a military plan develo...   \n",
       "5  Portland State University and Boston Universit...   \n",
       "6  Agent Provocateur contained the biggest single...   \n",
       "7  What class was 6029,a four-cylinder, simple, n...   \n",
       "8  The 2003 Major League Soccer All-Star Game was...   \n",
       "9  The GUID Partition Table forms a part of which...   \n",
       "\n",
       "                                             context  \\\n",
       "0  [['Hurricane (Thirty Seconds to Mars song)', [...   \n",
       "1  [['Derek Carr', ['Derek Dallas Carr (born Marc...   \n",
       "2  [['Recluse', ['A recluse is a person who lives...   \n",
       "3  [['Jennifer Weiner', ['Jennifer Weiner (born M...   \n",
       "4  [['McDonnell FH Phantom', ['The McDonnell FH P...   \n",
       "5  [['Portland State University', ['Portland Stat...   \n",
       "6  [['Robert Poley', ['Robert Poley, or Pooley (f...   \n",
       "7  [['Hunter Valley Mining Locomotives', ['Hunter...   \n",
       "8  [['2010 MLS All-Star Game', ['The 2010 Major L...   \n",
       "9  [['Volume Table of Contents', ['In the IBM mai...   \n",
       "\n",
       "                                  answer  \\\n",
       "0         Steve Roland \"Pre\" Prefontaine   \n",
       "1                          Daniel Kanell   \n",
       "2                 the public and society   \n",
       "3                                   2005   \n",
       "4  United States Army Air Forces (USAAF)   \n",
       "5                                    yes   \n",
       "6                          November 1984   \n",
       "7                         The AD60 class   \n",
       "8                         StubHub Center   \n",
       "9  Unified Extensible Firmware Interface   \n",
       "\n",
       "                                    predicted_answer  \\\n",
       "0                                  Steve Prefontaine   \n",
       "1                                     Tim Hasselbeck   \n",
       "2                                       Nikola Tesla   \n",
       "3  In Her Shoes is a 2005 American comedy-drama f...   \n",
       "4                                               None   \n",
       "5  Portland State University and Boston Universit...   \n",
       "6                                           November   \n",
       "7                                               None   \n",
       "8                                     StubHub Center   \n",
       "9       Unified Extensible Firmware Interface (UEFI)   \n",
       "\n",
       "                                          path_taken  \\\n",
       "0  [route_question -> Multi-hop, answer_generatio...   \n",
       "1  [route_question -> Single-hop, answer_generati...   \n",
       "2  [route_question -> Multi-hop, answer_generatio...   \n",
       "3  [route_question -> Single-hop, answer_generati...   \n",
       "4  [route_question -> Multi-hop, answer_generatio...   \n",
       "5  [route_question -> LLM (Yes, both Portland Sta...   \n",
       "6  [route_question -> Single-hop, answer_generati...   \n",
       "7  [route_question -> Multi-hop, answer_generatio...   \n",
       "8  [route_question -> Multi-hop, answer_generatio...   \n",
       "9  [route_question -> Multi-hop, answer_generatio...   \n",
       "\n",
       "                                   retrieved_context       time  \n",
       "0  [{'iteration': 1, 'content': 'Document 1:\n",
       "Hurr...  17.189109  \n",
       "1  [page_content='Derek Carr Derek Dallas Carr (b...   3.111104  \n",
       "2  [{'iteration': 1, 'content': 'Document 1:\n",
       "Recl...  15.325993  \n",
       "3  [page_content='Jennifer Weiner Jennifer Weiner...   3.269786  \n",
       "4  [{'iteration': 1, 'content': 'Document 1:\n",
       "McDo...  15.491253  \n",
       "5                                                 []   1.758760  \n",
       "6  [page_content='Robert Poley Robert Poley, or P...   3.287352  \n",
       "7  [{'iteration': 1, 'content': 'Document 1:\n",
       "Hunt...  15.941521  \n",
       "8  [{'iteration': 1, 'content': 'Document 1:\n",
       "2010...  10.040618  \n",
       "9  [{'iteration': 1, 'content': 'Document 1:\n",
       "Volu...  10.536506  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "_xePPrSKkPOr",
   "metadata": {
    "id": "_xePPrSKkPOr"
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"Adaptive_RAG_on_HotpotQA_dataset_Llama3B.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VDouZ3aqlpLr",
   "metadata": {
    "id": "VDouZ3aqlpLr"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0157b13b6bcd4b38aa4419d0674096b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_469e88cfb2b7421d8d366916b9c7067a",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_cfd3b092c70641c49b0d357ab4f59872",
      "value": "‚Äá612/612‚Äá[00:00&lt;00:00,‚Äá54.2kB/s]"
     }
    },
    "06b82056a2fa4fcba577ba0a03b89926": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_898a789aa32a46abb25029dc1545352f",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_8617a1e2b0314dd59f03d44a1b4c7afe",
      "value": "config.json:‚Äá100%"
     }
    },
    "0bf68d5cfaab4d38b05b2edcaa320e00": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0cad5c326f7048b0aeee3fb2ca0a2a60": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_51f97a0a94ed472e98d2cb1f4dd2a316",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_276450ab1ced46189125c672bf3effd0",
      "value": "‚Äá10.5k/10.5k‚Äá[00:00&lt;00:00,‚Äá650kB/s]"
     }
    },
    "0cc74cdc195740a7b6a521cd4ba37c11": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "13d1b5392cd54e08b97b6f424d43fe2f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "142e310294e741db852fb0b708a10711": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e175c86f280d426b9806a66905c92afa",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_1818242a211d4c71801ee4256a619b4a",
      "value": "‚Äá112/112‚Äá[00:00&lt;00:00,‚Äá7.23kB/s]"
     }
    },
    "1818242a211d4c71801ee4256a619b4a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1b1a61b152624ffd8415df06d19a80eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eaa50630d72849bc8eebed94243bf355",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_3fc67033c345471fbbfca0b32dbccef9",
      "value": "‚Äá349/349‚Äá[00:00&lt;00:00,‚Äá23.0kB/s]"
     }
    },
    "1bdcf2c6f54047119e0d21c06e14ae27": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1d295af551d34899bec8e5d7a48f5e6e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1db5ebaf482346908fc73eb1cb1db01c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_24b2c50405c74c769bbcd342f33df905",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_91db908a54f44446bd644f69533f4c28",
      "value": "‚Äá53.0/53.0‚Äá[00:00&lt;00:00,‚Äá3.38kB/s]"
     }
    },
    "1ee53bdbd44e4a8b8f3eb0fa722059aa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "212b509b1ca148ea84c1a62e90fe0d74": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "23c0ad606bab4d9fa86286cd3d7234fc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "24b2c50405c74c769bbcd342f33df905": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "276450ab1ced46189125c672bf3effd0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2b0b41c3404f4944b2b2325c86bdc2f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c67ac1e526a14a0490c8cd10fffc356b",
      "max": 350,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e1904f17f6214acabb3282eef0a7684e",
      "value": 350
     }
    },
    "2c080d428dca45d093101012d025f018": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2c78b76c5d1b42b8afbc8ce0ba2391ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8b1ce44ed2de4da4a640767844e39e04",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_d44fe1775cf9414699d2dd388a6f894a",
      "value": "‚Äá90.9M/90.9M‚Äá[00:01&lt;00:00,‚Äá95.7MB/s]"
     }
    },
    "30a30da0d80040b2925990088a3bd20f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6590dafe6c2541c08d377c4e89ba6060",
       "IPY_MODEL_72a07e60b7cd43f0bc5c3d43dfcf7353",
       "IPY_MODEL_2c78b76c5d1b42b8afbc8ce0ba2391ac"
      ],
      "layout": "IPY_MODEL_46f17740259b468abcc5096f106b1cda"
     }
    },
    "31d98e2b4a8e44e197cc37306c2c9d4d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "33085e168f7d43a99476512903c8483d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "352b4c329e0841f798e0c81ca062607f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "368c1f180b424d9f990966e9a5d065fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_caa49f5b053f42f59e87065e3943302c",
       "IPY_MODEL_39b5869a853f4ef893f195c89dc601cb",
       "IPY_MODEL_0157b13b6bcd4b38aa4419d0674096b5"
      ],
      "layout": "IPY_MODEL_ac268620a75745b495bbaa55ce6fde80"
     }
    },
    "3902b277c92e4095908d35cda0ff76ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_13d1b5392cd54e08b97b6f424d43fe2f",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7af14fc2f90f4d62943fc1453d356f81",
      "value": 231508
     }
    },
    "39b5869a853f4ef893f195c89dc601cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_da47492dda374035ada126283b204393",
      "max": 612,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9e8da3c4621d495aabddd32e73548d61",
      "value": 612
     }
    },
    "3af7c08c7c40401ba22c20375bc595f8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3d14d60cb957446e86071bdcd44cf088": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3fc67033c345471fbbfca0b32dbccef9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4330e997404945b386680fee7f0ebccd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "436fa04b7b094c9db66acf1c41a14f01": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_79ccddad3e3147c6a273de828cceb789",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_656c8792fab7492593edced268095e51",
      "value": "tokenizer_config.json:‚Äá100%"
     }
    },
    "469e88cfb2b7421d8d366916b9c7067a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "46f17740259b468abcc5096f106b1cda": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4797758b312845e0ac7a547605d1184c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4a3c608a1f6044639eb633dae104e0bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_abdaf4e9b1df4b24a2153b4aadd1610f",
       "IPY_MODEL_527612353f544d50a0fd1c6701c943ab",
       "IPY_MODEL_142e310294e741db852fb0b708a10711"
      ],
      "layout": "IPY_MODEL_dbc48a4318ae465089d727579b6bf9ae"
     }
    },
    "4caa901ef7194d1697473fffb4b43bd5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4cb642fcdd1242d0876c5d9e59769f19": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "51f97a0a94ed472e98d2cb1f4dd2a316": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "527612353f544d50a0fd1c6701c943ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7253ca85cbf04f0fb3f885dc7deddc51",
      "max": 112,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_80a54bbf87294e05bf67462185896ee9",
      "value": 112
     }
    },
    "57cae7c1fddd4709a830c66e05128ef1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f9575eaa01964a28a392d6b86e121036",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_87e5891ce940469c97c7193631c63c16",
      "value": "‚Äá232k/232k‚Äá[00:00&lt;00:00,‚Äá4.78MB/s]"
     }
    },
    "5a286d3b6705489eb080e129c6a7de58": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5d3a33f90dff4945a2db959053de8d17": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5da7e86a6f314df3bd36d61dd5f3676f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4cb642fcdd1242d0876c5d9e59769f19",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_33085e168f7d43a99476512903c8483d",
      "value": "README.md:‚Äá100%"
     }
    },
    "611792bd796a4c41a496b1c1fbee751c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "62fc9a6e9c884edba771e69b7a240409": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "63a3654c07234a7ba4fe165a2d16e2f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ea45942415b44ee1a11baeb2fdb9194d",
      "max": 466247,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_212b509b1ca148ea84c1a62e90fe0d74",
      "value": 466247
     }
    },
    "656c8792fab7492593edced268095e51": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6590dafe6c2541c08d377c4e89ba6060": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4caa901ef7194d1697473fffb4b43bd5",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_e991ec2eb138400b9f86c00b7749d990",
      "value": "model.safetensors:‚Äá100%"
     }
    },
    "68a3aadf43674db99edab88d356a64e8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6a5390914542474e8f5d37b903bbb5cc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6b41713f5556408ea1f362682ab1494e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6f4d0e653409467c99e16c1ae2bd2e5e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7253ca85cbf04f0fb3f885dc7deddc51": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "72a07e60b7cd43f0bc5c3d43dfcf7353": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_23c0ad606bab4d9fa86286cd3d7234fc",
      "max": 90868376,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3d14d60cb957446e86071bdcd44cf088",
      "value": 90868376
     }
    },
    "78a02368532f449e85885c503cfa96d4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "78d41bb260d64c92a338974955b47081": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0cc74cdc195740a7b6a521cd4ba37c11",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_ecb3f87a5ff5485fadc1763e00e70aec",
      "value": "config_sentence_transformers.json:‚Äá100%"
     }
    },
    "794dc7ba8e534f89bec002a1f2253699": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6b41713f5556408ea1f362682ab1494e",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_5a286d3b6705489eb080e129c6a7de58",
      "value": "sentence_bert_config.json:‚Äá100%"
     }
    },
    "79ccddad3e3147c6a273de828cceb789": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7a8cdcbd19234e45a56e1992f5cd0770": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_78d41bb260d64c92a338974955b47081",
       "IPY_MODEL_973a9bda79a24110bcfa06928dd624d8",
       "IPY_MODEL_a4fdd8378e7b4451ad2181bcca81f835"
      ],
      "layout": "IPY_MODEL_1d295af551d34899bec8e5d7a48f5e6e"
     }
    },
    "7af14fc2f90f4d62943fc1453d356f81": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7bb00f08f04d4c79925f7b4b97667cb2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_68a3aadf43674db99edab88d356a64e8",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_62fc9a6e9c884edba771e69b7a240409",
      "value": "‚Äá466k/466k‚Äá[00:00&lt;00:00,‚Äá23.6MB/s]"
     }
    },
    "80a54bbf87294e05bf67462185896ee9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8375e10665e24ddfa660065e056da6ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_794dc7ba8e534f89bec002a1f2253699",
       "IPY_MODEL_e1e7fb1a444244019159607466ff0d99",
       "IPY_MODEL_1db5ebaf482346908fc73eb1cb1db01c"
      ],
      "layout": "IPY_MODEL_c482a53409c54ccc87223f84bb27af48"
     }
    },
    "841a55a84315476a83c406790c405df3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3af7c08c7c40401ba22c20375bc595f8",
      "max": 349,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f202454d9f8344ec9c175af8d7870d47",
      "value": 349
     }
    },
    "8617a1e2b0314dd59f03d44a1b4c7afe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "86f12aca40184e5eb7529c4a9d84a080": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "87e5891ce940469c97c7193631c63c16": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "898a789aa32a46abb25029dc1545352f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8b1ce44ed2de4da4a640767844e39e04": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8d99baa20e0b480fb2117899bfbd2222": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5da7e86a6f314df3bd36d61dd5f3676f",
       "IPY_MODEL_9131906b6cd34ad4b9e34710d877d47f",
       "IPY_MODEL_0cad5c326f7048b0aeee3fb2ca0a2a60"
      ],
      "layout": "IPY_MODEL_1ee53bdbd44e4a8b8f3eb0fa722059aa"
     }
    },
    "900368265bd045f2bbcdfbd8a9895f21": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bbe4497064244c1687b2b8523d4b8f30",
       "IPY_MODEL_3902b277c92e4095908d35cda0ff76ec",
       "IPY_MODEL_57cae7c1fddd4709a830c66e05128ef1"
      ],
      "layout": "IPY_MODEL_fdffbbb8669c47178c7f7ba38ff8354d"
     }
    },
    "9131906b6cd34ad4b9e34710d877d47f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d6f8f2235d374a838426a42e86b2bc3e",
      "max": 10454,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9bf84dd8b7294235a2a323ed338882ae",
      "value": 10454
     }
    },
    "91db908a54f44446bd644f69533f4c28": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "973a9bda79a24110bcfa06928dd624d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bfdc4a6fc8534e65b93659729e37db90",
      "max": 116,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a7ae829da2984716be11dbe64bd07e13",
      "value": 116
     }
    },
    "9abd7207949043669bc33a79e72972a9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9bf84dd8b7294235a2a323ed338882ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9de5a2f7db5b4c10af1e35971e5197b5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9e8da3c4621d495aabddd32e73548d61": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a23250ed855441a0b7e788354601821f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a4fdd8378e7b4451ad2181bcca81f835": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9de5a2f7db5b4c10af1e35971e5197b5",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_e389c9ffe3454f148da787cf336f5fa8",
      "value": "‚Äá116/116‚Äá[00:00&lt;00:00,‚Äá7.46kB/s]"
     }
    },
    "a7ae829da2984716be11dbe64bd07e13": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "abdaf4e9b1df4b24a2153b4aadd1610f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fe86b4a6be7948b28b2d39b6899275ba",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_a23250ed855441a0b7e788354601821f",
      "value": "special_tokens_map.json:‚Äá100%"
     }
    },
    "ac268620a75745b495bbaa55ce6fde80": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b875c8e4473b4c18b3f90965762b695e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_06b82056a2fa4fcba577ba0a03b89926",
       "IPY_MODEL_ec777263a80646e7b382198c128d03d6",
       "IPY_MODEL_f9b9fa59176f428b9dd1e0aeacbc93e1"
      ],
      "layout": "IPY_MODEL_78a02368532f449e85885c503cfa96d4"
     }
    },
    "bbe4497064244c1687b2b8523d4b8f30": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1bdcf2c6f54047119e0d21c06e14ae27",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_2c080d428dca45d093101012d025f018",
      "value": "vocab.txt:‚Äá100%"
     }
    },
    "bfdc4a6fc8534e65b93659729e37db90": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c2f798cd67d54337a9c6610328a496d1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c482a53409c54ccc87223f84bb27af48": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c67ac1e526a14a0490c8cd10fffc356b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c9d48e50b9464fa4ba582f726817c2e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "caa49f5b053f42f59e87065e3943302c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9abd7207949043669bc33a79e72972a9",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_6f4d0e653409467c99e16c1ae2bd2e5e",
      "value": "config.json:‚Äá100%"
     }
    },
    "cfd3b092c70641c49b0d357ab4f59872": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d0a95093530e4fc3a5f11bc9cbd1c5a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d6f8ce3191c84671be4f5dcc1adb703a",
       "IPY_MODEL_841a55a84315476a83c406790c405df3",
       "IPY_MODEL_1b1a61b152624ffd8415df06d19a80eb"
      ],
      "layout": "IPY_MODEL_352b4c329e0841f798e0c81ca062607f"
     }
    },
    "d2e472eb10bf4b368558422b4c11c784": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e46c9d75aa88407daeb381f24dc97f94",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_4330e997404945b386680fee7f0ebccd",
      "value": "‚Äá350/350‚Äá[00:00&lt;00:00,‚Äá29.1kB/s]"
     }
    },
    "d39d4ed14b3f47cb9d09e5dd02ef6f2b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c2f798cd67d54337a9c6610328a496d1",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_c9d48e50b9464fa4ba582f726817c2e7",
      "value": "tokenizer.json:‚Äá100%"
     }
    },
    "d44fe1775cf9414699d2dd388a6f894a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d6f8ce3191c84671be4f5dcc1adb703a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_611792bd796a4c41a496b1c1fbee751c",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_ec441dd111bd444094efedb0e974ab48",
      "value": "modules.json:‚Äá100%"
     }
    },
    "d6f8f2235d374a838426a42e86b2bc3e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "da09e76cdc6f432ca514b119f8870296": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "da47492dda374035ada126283b204393": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dbc48a4318ae465089d727579b6bf9ae": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dfd46efadf134d8982ec861883336740": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_436fa04b7b094c9db66acf1c41a14f01",
       "IPY_MODEL_2b0b41c3404f4944b2b2325c86bdc2f2",
       "IPY_MODEL_d2e472eb10bf4b368558422b4c11c784"
      ],
      "layout": "IPY_MODEL_6a5390914542474e8f5d37b903bbb5cc"
     }
    },
    "e175c86f280d426b9806a66905c92afa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e1904f17f6214acabb3282eef0a7684e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e1e7fb1a444244019159607466ff0d99": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4797758b312845e0ac7a547605d1184c",
      "max": 53,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_31d98e2b4a8e44e197cc37306c2c9d4d",
      "value": 53
     }
    },
    "e389c9ffe3454f148da787cf336f5fa8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e46c9d75aa88407daeb381f24dc97f94": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e991ec2eb138400b9f86c00b7749d990": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ea45942415b44ee1a11baeb2fdb9194d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eaa50630d72849bc8eebed94243bf355": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ec441dd111bd444094efedb0e974ab48": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ec777263a80646e7b382198c128d03d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f5c811639b924f2f849c6a2faa2ce825",
      "max": 190,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_86f12aca40184e5eb7529c4a9d84a080",
      "value": 190
     }
    },
    "ecb3f87a5ff5485fadc1763e00e70aec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f19c9db3c8ac4f08a4314bfda621439b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d39d4ed14b3f47cb9d09e5dd02ef6f2b",
       "IPY_MODEL_63a3654c07234a7ba4fe165a2d16e2f1",
       "IPY_MODEL_7bb00f08f04d4c79925f7b4b97667cb2"
      ],
      "layout": "IPY_MODEL_5d3a33f90dff4945a2db959053de8d17"
     }
    },
    "f202454d9f8344ec9c175af8d7870d47": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f5c811639b924f2f849c6a2faa2ce825": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f9575eaa01964a28a392d6b86e121036": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f9b9fa59176f428b9dd1e0aeacbc93e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0bf68d5cfaab4d38b05b2edcaa320e00",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_da09e76cdc6f432ca514b119f8870296",
      "value": "‚Äá190/190‚Äá[00:00&lt;00:00,‚Äá12.3kB/s]"
     }
    },
    "fdffbbb8669c47178c7f7ba38ff8354d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fe86b4a6be7948b28b2d39b6899275ba": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
